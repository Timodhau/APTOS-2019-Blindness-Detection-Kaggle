{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib inline\n",
    "from torchsummary import summary\n",
    "\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pretrainedmodels\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "train_on_gpu = True\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "from albumentations import torch as AT\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aptos2019-blindness-detection.zip', 'test_images.zip', 'resnet50-regression.bin', 'train_images.zip', 'aptos']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../aptos/\"\n",
    "input_size = (3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH+'train.csv')\n",
    "test = pd.read_csv(PATH+'test.csv')\n",
    "sample_submission = pd.read_csv(PATH+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlassDataset(Dataset):\n",
    "    def __init__(self, df, datatype='train',transform=transforms.Compose([transforms.CenterCrop(32),transforms.ToTensor()]),y = None):\n",
    "        self.df = df\n",
    "        self.datatype = datatype\n",
    "        self.image_files_list = [f'../aptos/{self.datatype}_images/{i}.png' for i in df['id_code'].values]\n",
    "        if self.datatype == 'train':\n",
    "            self.labels = y\n",
    "        else:\n",
    "            self.labels = np.zeros((df.shape[0]))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files_list[idx]\n",
    "        img = cv2.imread(img_name)\n",
    "        if img.shape[2] == 1:\n",
    "            img = np.stack((img[..., 0],) * 3, axis=-1)\n",
    "            \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image=img)\n",
    "        image = image['image']\n",
    "\n",
    "        img_name_short = self.image_files_list[idx].split('.')[0]\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        if self.datatype == 'test':\n",
    "            return image, label, img_name\n",
    "        else:\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [1.5, 2.5, 3.5, 4.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        print(self.coef_)\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_(nn.Module):\n",
    "    def __init__(self, feature=2048, num_classes=1, inchannels=3, model_name='resnet50',pooling='concat'):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.feature = feature\n",
    "        self.pooling = pooling\n",
    "        \n",
    "        if model_name in pretrainedmodels.model_names:\n",
    "            self.base = pretrainedmodels.__dict__[self.model_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.base = torch.nn.Sequential(*(list(self.base.children())[:-2]))\n",
    "            self.base.load_state_dict(torch.load(PATH+\"checkpoint/resnet50-regression-0.7.bin\"))\n",
    "        else:\n",
    "            assert False, \"{} is error\".format(model_name)\n",
    "        \n",
    "        if self.pooling == 'concat':\n",
    "            print('Concatenated pooling')\n",
    "            self.ap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.mp = nn.AdaptiveMaxPool2d((1,1))\n",
    "            self.bn0 = nn.BatchNorm1d(self.feature*2,eps=1e-05, momentum=0.1, affine=True)\n",
    "            self.dropout0 = nn.Dropout(0.35)\n",
    "            self.fc1 = nn.Linear(self.feature*2, int(self.feature/2))\n",
    "            self.bn1 = nn.BatchNorm1d(int(self.feature/2),eps=1e-05, momentum=0.1, affine=True)\n",
    "            self.dropout1 = nn.Dropout(0.35)\n",
    "            self.fc2 = nn.Linear(int(self.feature/2), num_classes)\n",
    "        else:\n",
    "            if self.pooling == 'average': \n",
    "                self.ap = nn.AdaptiveAvgPool2d((1,1))\n",
    "                print('Average pooling')\n",
    "            if self.pooling == 'max': \n",
    "                self.mp = nn.AdaptiveMaxPool2d((1,1))\n",
    "                print('Max pooling')\n",
    "            self.bn0 = nn.BatchNorm1d(self.feature,eps=1e-05, momentum=0.1, affine=True)\n",
    "            self.dropout0 = nn.Dropout(0.35)\n",
    "            self.fc1 = nn.Linear(self.feature, int(self.feature/2))\n",
    "            self.bn1 = nn.BatchNorm1d(int(self.feature/2),eps=1e-05, momentum=0.1, affine=True)\n",
    "            self.dropout1 = nn.Dropout(0.35)\n",
    "            self.fc2 = nn.Linear(int(self.feature/2), num_classes)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        \n",
    "        if self.pooling == 'concat':\n",
    "            ap = self.ap(x)\n",
    "            mp = self.mp(x)\n",
    "            x = torch.cat((ap,mp),dim=1)\n",
    "            x = x.view(x.size(0), -1)  #Flatten\n",
    "            \n",
    "        if self.pooling == 'max':\n",
    "            x = self.mp(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            \n",
    "        if self.pooling == 'average':\n",
    "            x = self.ap(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "    \n",
    "        x = self.bn0(x)\n",
    "        x = self.dropout0(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)         \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated pooling\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "AdaptiveMaxPool2d-174           [-1, 2048, 1, 1]               0\n",
      "     BatchNorm1d-175                 [-1, 4096]           8,192\n",
      "         Dropout-176                 [-1, 4096]               0\n",
      "          Linear-177                 [-1, 1024]       4,195,328\n",
      "     BatchNorm1d-178                 [-1, 1024]           2,048\n",
      "         Dropout-179                 [-1, 1024]               0\n",
      "          Linear-180                    [-1, 1]           1,025\n",
      "================================================================\n",
      "Total params: 27,714,625\n",
      "Trainable params: 27,714,625\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.65\n",
      "Params size (MB): 105.72\n",
      "Estimated Total Size (MB): 392.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = model_(pooling='concat')\n",
    "model = model.to(device)\n",
    "summary(model, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = albumentations.Compose([\n",
    "    albumentations.Resize(input_size[1], input_size[2]),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.Flip(p=0.0),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.CLAHE(clip_limit=2), albumentations.IAASharpen(), albumentations.IAAEmboss(), \n",
    "        albumentations.RandomBrightness(), albumentations.RandomContrast(),\n",
    "        albumentations.JpegCompression(), albumentations.Blur(), albumentations.GaussNoise()], p=0.5), \n",
    "    albumentations.HueSaturationValue(p=0.5), \n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.15, rotate_limit=45, p=0.5),\n",
    "    albumentations.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "    AT.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 4\n",
    "lr = 0.01\n",
    "y = train['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GlassDataset(df=train, datatype='train',transform=data_transforms,y=y)\n",
    "\n",
    "tr, val = train_test_split(train.diagnosis, stratify=train.diagnosis, test_size=0.2)\n",
    "train_sampler = SubsetRandomSampler(list(tr.index))\n",
    "valid_sampler = SubsetRandomSampler(list(val.index))\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99), weight_decay=0.0002)\n",
    "\n",
    "optimizer = optim.Adam([{'params': model.fc1.parameters(),'lr':0.0064},\n",
    "                        {'params': model.fc2.parameters(),'lr':0.0064},\n",
    "                        {'params': model.base.parameters(), 'lr': 1e-4}], \n",
    "                       weight_decay=0.0002)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6456e5e5555146a3bda4d3c0e1119401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 61.4392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418b60d5905848ed90c71a581a74130e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=733), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " final_simplex: (array([[0.57697895, 2.80547232, 3.78523498, 5.27120441],\n",
      "       [0.5769791 , 2.80548058, 3.78515094, 5.27115165],\n",
      "       [0.57697036, 2.80550243, 3.7851676 , 5.27111111],\n",
      "       [0.57698328, 2.805481  , 3.78516765, 5.27111419],\n",
      "       [0.57696903, 2.80548462, 3.78517707, 5.27115308]]), array([-0.44801707, -0.44801707, -0.44801707, -0.44801707, -0.44801707]))\n",
      "           fun: -0.4480170680215848\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 122\n",
      "           nit: 46\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.57697895, 2.80547232, 3.78523498, 5.27120441])\n",
      "Accuracy : 0.3834\n",
      "Kappa : 0.1816\n",
      "F1 score: 0.4156\n",
      "1 epochs oµf increasing val loss\n",
      "Epoch 1/99\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1c9967d27f45218a644f0b93d7b703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 29.4360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d68db6e76b5401b9c07de2ae60edc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=733), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " final_simplex: (array([[0.01031505, 0.47938555, 5.2385328 , 8.06663449],\n",
      "       [0.01032671, 0.47938018, 5.23856713, 8.06658774],\n",
      "       [0.01032154, 0.47937079, 5.23858253, 8.06657738],\n",
      "       [0.01029919, 0.47934181, 5.23860701, 8.06665066],\n",
      "       [0.01031014, 0.47941564, 5.23857543, 8.06657921]]), array([-0.78926709, -0.78926709, -0.78926709, -0.78926709, -0.78926709]))\n",
      "           fun: -0.7892670872957217\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 122\n",
      "           nit: 42\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.01031505, 0.47938555, 5.2385328 , 8.06663449])\n",
      "Accuracy : 0.7435\n",
      "Kappa : 0.5930\n",
      "F1 score: 0.6872\n",
      "2 epochs oµf increasing val loss\n",
      "Epoch 2/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iilab/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3060b2731ab4945bfefdd02eb72eb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 22.7764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dce028501340e68b3f33aa9183f35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=733), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " final_simplex: (array([[0.88119979, 0.25283042, 5.17681779, 6.11430579],\n",
      "       [0.88119367, 0.25283504, 5.17681593, 6.11427307],\n",
      "       [0.8811863 , 0.25286937, 5.17681901, 6.11427916],\n",
      "       [0.88120002, 0.25291574, 5.17675237, 6.11425971],\n",
      "       [0.88120686, 0.25292187, 5.17676549, 6.11424265]]), array([-0.77250525, -0.77250525, -0.77250525, -0.77250525, -0.77250525]))\n",
      "           fun: -0.7725052517449347\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 110\n",
      "           nit: 33\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.88119979, 0.25283042, 5.17681779, 6.11430579])\n",
      "Accuracy : 0.7422\n",
      "Kappa : 0.5791\n",
      "F1 score: 0.6596\n",
      "3 epochs oµf increasing val loss\n",
      "Epoch 3/99\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea105dc9bb264087bf28f5574f1c2147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 22.3200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7140bbd3254c42d5a2ea79d6f474a8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=733), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " final_simplex: (array([[0.74299007, 1.19067239, 2.20340718, 8.27367109],\n",
      "       [0.74298859, 1.19064394, 2.2034073 , 8.27374462],\n",
      "       [0.74298137, 1.1906823 , 2.20341869, 8.27368516],\n",
      "       [0.74298689, 1.1906597 , 2.20342108, 8.27369522],\n",
      "       [0.74298398, 1.19063719, 2.20340665, 8.27373288]]), array([-0.80297053, -0.80297053, -0.80297053, -0.80297053, -0.80297053]))\n",
      "           fun: -0.8029705283351793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 147\n",
      "           nit: 62\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.74299007, 1.19067239, 2.20340718, 8.27367109])\n",
      "Accuracy : 0.6235\n",
      "Kappa : 0.4521\n",
      "F1 score: 0.6142\n",
      "4 epochs oµf increasing val loss\n",
      "Epoch 4/99\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83977076c0cb4bac9252ab6a3cd30292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 20.3973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aaec2bb7c648a5b7affea7d94fdf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=733), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " final_simplex: (array([[1.18715731, 1.32909153, 4.11851403, 4.91462383],\n",
      "       [1.18710632, 1.32906048, 4.11860838, 4.91458052],\n",
      "       [1.18712844, 1.32910969, 4.11856116, 4.91459996],\n",
      "       [1.18712485, 1.32903752, 4.11854594, 4.91464979],\n",
      "       [1.18713111, 1.32903126, 4.11856723, 4.91464774]]), array([-0.77678361, -0.77678361, -0.77678361, -0.77678361, -0.77678361]))\n",
      "           fun: -0.7767836132650829\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 119\n",
      "           nit: 41\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.18715731, 1.32909153, 4.11851403, 4.91462383])\n",
      "Accuracy : 0.7422\n",
      "Kappa : 0.5839\n",
      "F1 score: 0.6710\n",
      "5 epochs oµf increasing val loss\n",
      "Epoch 5/99\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595bdc9016244fa7bc22db4a8b0fb2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 20.2054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63c08a69858486a8388dbb9c29c61a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=733), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_kappa = 0.7\n",
    "patience = 5\n",
    "# current number of epochs, where validation loss didn't increase\n",
    "p = 0\n",
    "# whether training should be stopped\n",
    "stop = False\n",
    "\n",
    "since = time.time()\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    scheduler.step()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for bi, (data, target) in enumerate(tk0):\n",
    "        inputs = data\n",
    "        labels = target.view(-1, 1)\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        counter += 1\n",
    "        tk0.set_postfix(loss=(running_loss / (counter * train_loader.batch_size)))\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print('Training Loss: {:.4f}'.format(epoch_loss))\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    val_auc = []\n",
    "    \n",
    "    val_target = np.zeros(len(val))\n",
    "    val_pred = np.zeros(len(val))\n",
    "    tk1 = tqdm(valid_loader)\n",
    "    for batch_i, (data, target) in enumerate(tk1):\n",
    "        inputs = data\n",
    "        labels = target.view(-1, 1)\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_loss.append(loss.item()) \n",
    "        a = target.data.cpu().numpy()\n",
    "        b = outputs.detach().cpu().numpy()\n",
    "        val_target[batch_i] = a\n",
    "        val_pred[batch_i] = b\n",
    "        \n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(val_pred, val_target)\n",
    "    coefficients = optR.coefficients()\n",
    "    valid_predictions = optR.predict(val_pred, coefficients)\n",
    "    \n",
    "    accuracy = accuracy_score(val_target, valid_predictions)\n",
    "    print('Accuracy : {:.4f}'.format(accuracy))\n",
    "    kappa = metrics.cohen_kappa_score(val_target, valid_predictions, labels=None, weights=None, sample_weight=None)\n",
    "    print('Kappa : {:.4f}'.format(kappa))\n",
    "    f1 = f1_score(val_target, valid_predictions, labels=None, pos_label=1, average='weighted', sample_weight=None)\n",
    "    print('F1 score: {:.4f}'.format(f1))\n",
    "    if best_kappa<kappa:\n",
    "        best_kappa = kappa\n",
    "        torch.save(model.state_dict(), \"../aptos/checkpoint/resnet50-\"+format(kappa)+\".bin\")\n",
    "        print('Model save')\n",
    "    if best_kappa > kappa:\n",
    "        p += 1\n",
    "        print(f'{p} epochs oµf increasing val loss')\n",
    "        if p > patience:\n",
    "            print('Stopping training')\n",
    "            stop = True\n",
    "            break        \n",
    "            \n",
    "    if stop:\n",
    "        break\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#torch.save(model.state_dict(), \"../aptos/checkpoint/resnet50\"+format(epoch_loss)+\"-regression.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GlassDataset(df=train, datatype='train',transform=data_transforms,y=y)\n",
    "\n",
    "tr, val = train_test_split(train.diagnosis, stratify=train.diagnosis, test_size=0.99)\n",
    "train_sampler = SubsetRandomSampler(list(tr.index))\n",
    "valid_sampler = SubsetRandomSampler(list(val.index))\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.eval()\n",
    "val_target = np.zeros(len(val))\n",
    "val_pred = np.zeros(len(val))\n",
    "tk1 = tqdm(valid_loader)\n",
    "for batch_i, (data, target) in enumerate(tk1):\n",
    "    inputs = data\n",
    "    labels = target.view(-1, 1)\n",
    "    inputs = inputs.to(device, dtype=torch.float)\n",
    "    labels = labels.to(device, dtype=torch.float)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    val_loss.append(loss.item()) \n",
    "    a = target.data.cpu().numpy()\n",
    "    b = outputs.detach().cpu().numpy()\n",
    "    val_target[batch_i] = a\n",
    "    val_pred[batch_i] = b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(val_pred, val_target)\n",
    "coefficients = optR.coefficients()\n",
    "valid_predictions = optR.predict(val_pred, coefficients)\n",
    "    \n",
    "accuracy = accuracy_score(val_target, valid_predictions)\n",
    "print('Accuracy : {:.4f}'.format(accuracy))\n",
    "kappa = metrics.cohen_kappa_score(val_target, valid_predictions, labels=None, weights=None, sample_weight=None)\n",
    "print('Kappa : {:.4f}'.format(kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((input_size[1], input_size[2])),\n",
    "    AT.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_set = GlassDataset(df=test, datatype='test', transform=data_transforms_test)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_preds = np.zeros((len(test_dataset), 1))\n",
    "tk0 = tqdm(test_data_loader)\n",
    "for i, x_batch in enumerate(tk0):\n",
    "    x_batch = x_batch[\"image\"]\n",
    "    pred = model(x_batch.to(device))\n",
    "    test_preds[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = [0.5, 1.5, 2.5, 3.5]\n",
    "\n",
    "for i, pred in enumerate(test_preds):\n",
    "    if pred < coef[0]:\n",
    "        test_preds[i] = 0\n",
    "    elif pred >= coef[0] and pred < coef[1]:\n",
    "        test_preds[i] = 1\n",
    "    elif pred >= coef[1] and pred < coef[2]:\n",
    "        test_preds[i] = 2\n",
    "    elif pred >= coef[2] and pred < coef[3]:\n",
    "        test_preds[i] = 3\n",
    "    else:\n",
    "        test_preds[i] = 4\n",
    "\n",
    "\n",
    "sample = pd.read_csv(PATH+\"sample_submission.csv\")\n",
    "sample.diagnosis = test_preds.astype(int)\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
